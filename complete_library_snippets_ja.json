{
  "metadata": {
    "exported_at": "2025-10-16T06:53:58.044951",
    "version": "1.0",
    "total_tags": 6,
    "total_snippets": 52
  },
  "tags": [
    {
      "id": 6,
      "name": "Django",
      "icon": "ğŸ“",
      "color": "#64B5F6",
      "parent_id": null,
      "type": "folder"
    },
    {
      "id": 2,
      "name": "Matplotlib",
      "icon": "ğŸ“",
      "color": "#64B5F6",
      "parent_id": null,
      "type": "folder"
    },
    {
      "id": 1,
      "name": "NumPy",
      "icon": "ğŸ“",
      "color": "#64B5F6",
      "parent_id": null,
      "type": "folder"
    },
    {
      "id": 3,
      "name": "Pandas",
      "icon": "ğŸ“",
      "color": "#64B5F6",
      "parent_id": null,
      "type": "folder"
    },
    {
      "id": 5,
      "name": "TensorFlow/Keras",
      "icon": "ğŸ“",
      "color": "#64B5F6",
      "parent_id": null,
      "type": "folder"
    },
    {
      "id": 4,
      "name": "scikit-learn",
      "icon": "ğŸ“",
      "color": "#64B5F6",
      "parent_id": null,
      "type": "folder"
    }
  ],
  "snippets": [
    {
      "name": "Array Creation",
      "code": "import numpy as np\n\n# Create arrays\narr1 = np.array([1, 2, 3, 4, 5])\narr2 = np.zeros((3, 4))\narr3 = np.ones((2, 3))\narr4 = np.arange(0, 10, 2)\narr5 = np.linspace(0, 1, 5)",
      "language": "python",
      "description": "NumPyé…åˆ—ã‚’ä½œæˆã™ã‚‹æ§˜ã€…ãªæ–¹æ³•",
      "tag_ids": [
        1
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Array Creation",
      "code": "import numpy as np\n\n# é…åˆ—ä½œæˆã®åŸºæœ¬\narr1 = np.array([1, 2, 3, 4, 5])\narr2 = np.zeros((3, 4))\narr3 = np.ones((2, 3))\narr4 = np.arange(0, 10, 2)\narr5 = np.linspace(0, 1, 5)\narr6 = np.eye(3)  # å˜ä½è¡Œåˆ—",
      "language": "python",
      "description": "NumPyé…åˆ—ã‚’ä½œæˆã™ã‚‹æ§˜ã€…ãªæ–¹æ³•ï¼ˆzeros, ones, arange, linspaceç­‰ï¼‰",
      "tag_ids": [
        1
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Array Indexing",
      "code": "import numpy as np\n\narr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã‚¹ãƒ©ã‚¤ã‚¹\nprint(arr[0, 1])      # 2 - ç‰¹å®šè¦ç´ \nprint(arr[1])         # [4, 5, 6] - è¡Œå…¨ä½“\nprint(arr[:2, 1:])    # [[2, 3], [5, 6]] - ã‚¹ãƒ©ã‚¤ã‚¹\nprint(arr[::2, ::2])  # [[1, 3], [7, 9]] - ã‚¹ãƒ†ãƒƒãƒ—ä»˜ã\n\n# Boolean ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹\nprint(arr[arr > 5])   # [6, 7, 8, 9] - æ¡ä»¶æŠ½å‡º\narr[arr > 5] = 0      # æ¡ä»¶ä»˜ãä»£å…¥",
      "language": "python",
      "description": "NumPyé…åˆ—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‚ç…§ã¨ã‚¹ãƒ©ã‚¤ã‚¹æŠ€æ³•ï¼ˆBoolean indexingå«ã‚€ï¼‰",
      "tag_ids": [
        1
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Array Indexing and Slicing",
      "code": "import numpy as np\n\narr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n# Indexing\nprint(arr[0, 1])      # 2\nprint(arr[1])         # [4, 5, 6]\n\n# Slicing\nprint(arr[:2, 1:])    # [[2, 3], [5, 6]]\nprint(arr[::2, ::2])  # [[1, 3], [7, 9]]\n\n# Boolean indexing\nprint(arr[arr > 5])   # [6, 7, 8, 9]",
      "language": "python",
      "description": "NumPyé…åˆ—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‚ç…§ã¨ã‚¹ãƒ©ã‚¤ã‚¹æŠ€æ³•",
      "tag_ids": [
        1
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Array Operations",
      "code": "import numpy as np\n\narr = np.array([[1, 2, 3], [4, 5, 6]])\n\n# Basic operations\nprint(arr.shape)      # (2, 3)\nprint(arr.ndim)       # 2\nprint(arr.dtype)      # int64\nprint(arr.sum())      # 21\nprint(arr.mean())     # 3.5\nprint(arr.max())      # 6",
      "language": "python",
      "description": "NumPyé…åˆ—ã®åŸºæœ¬çš„ãªæ“ä½œã¨ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£",
      "tag_ids": [
        1
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Array Operations",
      "code": "import numpy as np\n\narr = np.array([[1, 2, 3], [4, 5, 6]])\n\n# åŸºæœ¬çš„ãªæ“ä½œã¨å±æ€§\nprint(arr.shape)      # (2, 3) - é…åˆ—ã®å½¢çŠ¶\nprint(arr.ndim)       # 2 - æ¬¡å…ƒæ•°\nprint(arr.dtype)      # int64 - ãƒ‡ãƒ¼ã‚¿å‹\nprint(arr.size)       # 6 - è¦ç´ æ•°\nprint(arr.sum())      # 21 - åˆè¨ˆ\nprint(arr.mean())     # 3.5 - å¹³å‡\nprint(arr.std())      # æ¨™æº–åå·®\nprint(arr.max())      # 6 - æœ€å¤§å€¤\nprint(arr.min())      # 1 - æœ€å°å€¤",
      "language": "python",
      "description": "NumPyé…åˆ—ã®åŸºæœ¬çš„ãªæ“ä½œã¨ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ï¼ˆå½¢çŠ¶ã€çµ±è¨ˆé‡ãªã©ï¼‰",
      "tag_ids": [
        1
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Array Reshaping",
      "code": "import numpy as np\n\narr = np.arange(12)\n\n# å½¢çŠ¶å¤‰æ›´\nreshaped = arr.reshape(3, 4)  # (3, 4)ã«å¤‰å½¢\nreshaped = arr.reshape(2, -1) # -1ã§è‡ªå‹•è¨ˆç®—\nflattened = reshaped.flatten() # 1æ¬¡å…ƒåŒ–\nravel = reshaped.ravel()      # 1æ¬¡å…ƒåŒ–ï¼ˆãƒ“ãƒ¥ãƒ¼ï¼‰\n\n# æ¬¡å…ƒè¿½åŠ ãƒ»å‰Šé™¤\nexpanded = arr[np.newaxis, :]  # æ¬¡å…ƒè¿½åŠ \nsqueezed = np.squeeze(expanded) # ä¸è¦ãªæ¬¡å…ƒå‰Šé™¤",
      "language": "python",
      "description": "NumPyé…åˆ—ã®å½¢çŠ¶å¤‰æ›´ï¼ˆreshape, flatten, æ¬¡å…ƒæ“ä½œï¼‰",
      "tag_ids": [
        1
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Bar Chart",
      "code": "import matplotlib.pyplot as plt\n\ncategories = ['A', 'B', 'C', 'D', 'E']\nvalues = [23, 45, 56, 78, 32]\n\nplt.figure(figsize=(10, 6))\nplt.bar(categories, values, color='skyblue', edgecolor='navy')\nplt.xlabel('Category')\nplt.ylabel('Value')\nplt.title('Bar Chart Example')\nplt.grid(axis='y', alpha=0.3)\nplt.show()",
      "language": "python",
      "description": "æ£’ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ",
      "tag_ids": [
        2
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Bar Chart",
      "code": "import matplotlib.pyplot as plt\n\ncategories = ['A', 'B', 'C', 'D', 'E']\nvalues = [23, 45, 56, 78, 32]\n\nplt.figure(figsize=(10, 6))\nbars = plt.bar(categories, values, color='skyblue', edgecolor='navy', alpha=0.7)\nplt.xlabel('ã‚«ãƒ†ã‚´ãƒª')\nplt.ylabel('å€¤')\nplt.title('æ£’ã‚°ãƒ©ãƒ•ã®ä¾‹')\nplt.grid(axis='y', alpha=0.3)\n\n# å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., height,\n             f'{height}', ha='center', va='bottom')\n\nplt.show()",
      "language": "python",
      "description": "å€¤ãƒ©ãƒ™ãƒ«ä»˜ãã®æ£’ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ",
      "tag_ids": [
        2
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Basic Line Plot",
      "code": "import matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\n\nplt.figure(figsize=(10, 6))\nplt.plot(x, y, label='sin(x)')\nplt.xlabel('X axis')\nplt.ylabel('Y axis')\nplt.title('Sine Wave')\nplt.legend()\nplt.grid(True)\nplt.show()",
      "language": "python",
      "description": "Matplotlibã§åŸºæœ¬çš„ãªæŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•ã‚’ä½œæˆ",
      "tag_ids": [
        2
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Basic Line Plot",
      "code": "import matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\n\nplt.figure(figsize=(10, 6))\nplt.plot(x, y, label='sin(x)', linewidth=2)\nplt.xlabel('Xè»¸')\nplt.ylabel('Yè»¸')\nplt.title('ã‚µã‚¤ãƒ³æ³¢')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()",
      "language": "python",
      "description": "Matplotlibã§åŸºæœ¬çš„ãªæŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•ã‚’ä½œæˆï¼ˆãƒ©ãƒ™ãƒ«ã€å‡¡ä¾‹ã€ã‚°ãƒªãƒƒãƒ‰ä»˜ãï¼‰",
      "tag_ids": [
        2
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "CNN for Image Classification",
      "code": "from tensorflow import keras\nfrom tensorflow.keras import layers\n\nmodel = keras.Sequential([\n    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.Flatten(),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(10, activation='softmax')\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)",
      "language": "python",
      "description": "ç”»åƒåˆ†é¡ç”¨CNNãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ",
      "tag_ids": [
        5
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Class-Based View",
      "code": "from django.views.generic import ListView, DetailView, CreateView\nfrom django.urls import reverse_lazy\n\nclass ArticleListView(ListView):\n    model = Article\n    template_name = 'articles/list.html'\n    context_object_name = 'articles'\n    paginate_by = 10\n\n    def get_queryset(self):\n        return Article.objects.filter(published=True)\n\nclass ArticleDetailView(DetailView):\n    model = Article\n    template_name = 'articles/detail.html'\n\nclass ArticleCreateView(CreateView):\n    model = Article\n    fields = ['title', 'content', 'published']\n    success_url = reverse_lazy('article-list')",
      "language": "python",
      "description": "Djangoã®ã‚¯ãƒ©ã‚¹ãƒ™ãƒ¼ã‚¹ãƒ“ãƒ¥ãƒ¼ (CBV)",
      "tag_ids": [
        6
      ],
      "usage_count": 1,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Cross-Validation",
      "code": "from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Perform 5-fold cross-validation\nscores = cross_val_score(\n    model, X, y,\n    cv=5,                    # 5 folds\n    scoring='accuracy'       # Metric\n)\n\nprint(f\"CV Scores: {scores}\")\nprint(f\"Mean: {scores.mean():.4f}\")\nprint(f\"Std: {scores.std():.4f}\")",
      "language": "python",
      "description": "äº¤å·®æ¤œè¨¼ã‚’å®Ÿè¡Œ",
      "tag_ids": [
        4
      ],
      "usage_count": 1,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Cross-Validation",
      "code": "from sklearn.model_selection import cross_val_score, cross_validate\nfrom sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³\nscores = cross_val_score(\n    model, X, y,\n    cv=5,                    # 5åˆ†å‰²\n    scoring='accuracy'       # è©•ä¾¡æŒ‡æ¨™\n)\n\nprint(f\"CVã‚¹ã‚³ã‚¢: {scores}\")\nprint(f\"å¹³å‡: {scores.mean():.4f}\")\nprint(f\"æ¨™æº–åå·®: {scores.std():.4f}\")\n\n# è¤‡æ•°ã®è©•ä¾¡æŒ‡æ¨™ã§ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³\ncv_results = cross_validate(\n    model, X, y,\n    cv=5,\n    scoring=['accuracy', 'precision', 'recall', 'f1'],\n    return_train_score=True\n)\n\nprint(\"\nãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢:\")\nfor metric, scores in cv_results.items():\n    if metric.startswith('test_'):\n        print(f\"{metric}: {scores.mean():.4f} (+/- {scores.std():.4f})\")",
      "language": "python",
      "description": "äº¤å·®æ¤œè¨¼ã‚’å®Ÿè¡Œã—ã¦ãƒ¢ãƒ‡ãƒ«ã®æ±åŒ–æ€§èƒ½ã‚’è©•ä¾¡",
      "tag_ids": [
        4
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Data Cleaning",
      "code": "import pandas as pd\n\n# Handle missing values\ndf.dropna()                    # Drop rows with NaN\ndf.fillna(0)                   # Fill NaN with 0\ndf.fillna(df.mean())          # Fill with mean\n\n# Remove duplicates\ndf.drop_duplicates()\n\n# Rename columns\ndf.rename(columns={'old_name': 'new_name'})\n\n# Change data types\ndf['column'] = df['column'].astype('int')\n\n# Replace values\ndf['column'].replace({'old': 'new'})",
      "language": "python",
      "description": "DataFrameã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ»æ•´å½¢",
      "tag_ids": [
        3
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Data Cleaning",
      "code": "import pandas as pd\n\n# æ¬ æå€¤ã®å‡¦ç†\ndf.dropna()                    # æ¬ æå€¤ã‚’å«ã‚€è¡Œã‚’å‰Šé™¤\ndf.fillna(0)                   # æ¬ æå€¤ã‚’0ã§åŸ‹ã‚ã‚‹\ndf.fillna(df.mean())          # å¹³å‡å€¤ã§åŸ‹ã‚ã‚‹\ndf.fillna(method='ffill')     # å‰æ–¹è£œå®Œ\ndf.fillna(method='bfill')     # å¾Œæ–¹è£œå®Œ\n\n# é‡è¤‡ã®å‰Šé™¤\ndf.drop_duplicates()\ndf.drop_duplicates(subset=['col1'])\n\n# åˆ—åã®å¤‰æ›´\ndf.rename(columns={'old_name': 'new_name'})\n\n# ãƒ‡ãƒ¼ã‚¿å‹ã®å¤‰æ›´\ndf['column'] = df['column'].astype('int')\n\n# å€¤ã®ç½®æ›\ndf['column'].replace({'old': 'new'})",
      "language": "python",
      "description": "DataFrameã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ»æ•´å½¢ï¼ˆæ¬ æå€¤ã€é‡è¤‡ã€å‹å¤‰æ›ï¼‰",
      "tag_ids": [
        3
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Data Inspection",
      "code": "import pandas as pd\n\n# Basic info\nprint(df.shape)           # (rows, columns)\nprint(df.info())          # Data types and non-null counts\nprint(df.describe())      # Statistical summary\nprint(df.head(10))        # First 10 rows\nprint(df.tail(10))        # Last 10 rows\n\n# Column info\nprint(df.columns)         # Column names\nprint(df.dtypes)          # Data types\nprint(df.isnull().sum())  # Missing values per column",
      "language": "python",
      "description": "DataFrameã®æ§‹é€ ã¨å†…å®¹ã‚’æ¤œæŸ»",
      "tag_ids": [
        3
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Data Inspection",
      "code": "import pandas as pd\n\n# ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æƒ…å ±\nprint(df.shape)           # (è¡Œæ•°, åˆ—æ•°)\nprint(df.info())          # ãƒ‡ãƒ¼ã‚¿å‹ã¨énullæ•°\nprint(df.describe())      # çµ±è¨ˆã‚µãƒãƒªãƒ¼\nprint(df.head(10))        # å…ˆé ­10è¡Œ\nprint(df.tail(10))        # æœ«å°¾10è¡Œ\nprint(df.sample(5))       # ãƒ©ãƒ³ãƒ€ãƒ 5è¡Œ\n\n# åˆ—æƒ…å ±\nprint(df.columns)         # åˆ—å\nprint(df.dtypes)          # ãƒ‡ãƒ¼ã‚¿å‹\nprint(df.isnull().sum())  # æ¬ æå€¤ã®æ•°\nprint(df.nunique())       # ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤ã®æ•°",
      "language": "python",
      "description": "DataFrameã®æ§‹é€ ã¨å†…å®¹ã‚’è©³ç´°ã«æ¤œæŸ»ï¼ˆçµ±è¨ˆã€æ¬ æå€¤ãªã©ï¼‰",
      "tag_ids": [
        3
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Data Merging",
      "code": "import pandas as pd\n\n# DataFrameã®çµåˆ\ndf1 = pd.DataFrame({'key': ['A', 'B', 'C'], 'value1': [1, 2, 3]})\ndf2 = pd.DataFrame({'key': ['A', 'B', 'D'], 'value2': [4, 5, 6]})\n\n# ãƒãƒ¼ã‚¸ï¼ˆSQLã®JOINç›¸å½“ï¼‰\nmerged = pd.merge(df1, df2, on='key', how='inner')  # å†…éƒ¨çµåˆ\nmerged = pd.merge(df1, df2, on='key', how='outer')  # å¤–éƒ¨çµåˆ\nmerged = pd.merge(df1, df2, on='key', how='left')   # å·¦çµåˆ\n\n# é€£çµ\nconcatenated = pd.concat([df1, df2], axis=0)  # ç¸¦æ–¹å‘\nconcatenated = pd.concat([df1, df2], axis=1)  # æ¨ªæ–¹å‘",
      "language": "python",
      "description": "è¤‡æ•°ã®DataFrameã‚’çµåˆãƒ»é€£çµï¼ˆmerge, concatï¼‰",
      "tag_ids": [
        3
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Data Selection",
      "code": "import pandas as pd\n\n# Select columns\ndf['column_name']\ndf[['col1', 'col2']]\n\n# Select rows by index\ndf.iloc[0]           # First row\ndf.iloc[0:5]         # First 5 rows\ndf.iloc[:, 0:3]      # First 3 columns\n\n# Select by label\ndf.loc[0, 'column_name']\ndf.loc[:, ['col1', 'col2']]\n\n# Conditional selection\ndf[df['age'] > 30]\ndf[(df['age'] > 25) & (df['city'] == 'Tokyo')]",
      "language": "python",
      "description": "DataFrameã®ãƒ‡ãƒ¼ã‚¿ã‚’é¸æŠãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°",
      "tag_ids": [
        3
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Data Selection",
      "code": "import pandas as pd\n\n# åˆ—ã®é¸æŠ\ndf['column_name']\ndf[['col1', 'col2']]\n\n# è¡Œã®é¸æŠï¼ˆä½ç½®ãƒ™ãƒ¼ã‚¹ï¼‰\ndf.iloc[0]           # æœ€åˆã®è¡Œ\ndf.iloc[0:5]         # æœ€åˆã®5è¡Œ\ndf.iloc[:, 0:3]      # æœ€åˆã®3åˆ—\n\n# è¡Œã®é¸æŠï¼ˆãƒ©ãƒ™ãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰\ndf.loc[0, 'column_name']\ndf.loc[:, ['col1', 'col2']]\n\n# æ¡ä»¶é¸æŠ\ndf[df['age'] > 30]\ndf[(df['age'] > 25) & (df['city'] == 'Tokyo')]\ndf.query('age > 30 and city == \"Tokyo\"')",
      "language": "python",
      "description": "DataFrameã®ãƒ‡ãƒ¼ã‚¿ã‚’é¸æŠãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆiloc, loc, queryï¼‰",
      "tag_ids": [
        3
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "DataFrame Creation",
      "code": "import pandas as pd\n\n# From dictionary\ndf = pd.DataFrame({\n    'name': ['Alice', 'Bob', 'Charlie'],\n    'age': [25, 30, 35],\n    'city': ['Tokyo', 'Osaka', 'Kyoto']\n})\n\n# From CSV\ndf = pd.read_csv('data.csv')\n\n# From Excel\ndf = pd.read_excel('data.xlsx')\n\nprint(df.head())",
      "language": "python",
      "description": "Pandas DataFrameã‚’ä½œæˆã™ã‚‹æ§˜ã€…ãªæ–¹æ³•",
      "tag_ids": [
        3
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "DataFrame Creation",
      "code": "import pandas as pd\n\n# è¾æ›¸ã‹ã‚‰ä½œæˆ\ndf = pd.DataFrame({\n    'name': ['Alice', 'Bob', 'Charlie'],\n    'age': [25, 30, 35],\n    'city': ['Tokyo', 'Osaka', 'Kyoto']\n})\n\n# CSVã‹ã‚‰èª­ã¿è¾¼ã¿\ndf = pd.read_csv('data.csv')\n\n# Excelã‹ã‚‰èª­ã¿è¾¼ã¿\ndf = pd.read_excel('data.xlsx', sheet_name='Sheet1')\n\n# JSONã‹ã‚‰èª­ã¿è¾¼ã¿\ndf = pd.read_json('data.json')\n\nprint(df.head())",
      "language": "python",
      "description": "Pandas DataFrameã‚’ä½œæˆã™ã‚‹æ§˜ã€…ãªæ–¹æ³•ï¼ˆè¾æ›¸ã€CSVã€Excelã€JSONï¼‰",
      "tag_ids": [
        3
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Django Forms",
      "code": "from django import forms\nfrom .models import Article\n\nclass ArticleForm(forms.ModelForm):\n    class Meta:\n        model = Article\n        fields = ['title', 'content', 'published']\n        widgets = {\n            'title': forms.TextInput(attrs={'class': 'form-control'}),\n            'content': forms.Textarea(attrs={\n                'class': 'form-control',\n                'rows': 10\n            }),\n        }\n\n    def clean_title(self):\n        title = self.cleaned_data['title']\n        if len(title) < 5:\n            raise forms.ValidationError('Title must be at least 5 characters')\n        return title",
      "language": "python",
      "description": "ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ä»˜ãDjango ModelForm",
      "tag_ids": [
        6
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Django REST Framework ViewSet",
      "code": "from rest_framework import viewsets\nfrom rest_framework.permissions import IsAuthenticatedOrReadOnly\nfrom .models import Article\nfrom .serializers import ArticleSerializer\n\nclass ArticleViewSet(viewsets.ModelViewSet):\n    queryset = Article.objects.all()\n    serializer_class = ArticleSerializer\n    permission_classes = [IsAuthenticatedOrReadOnly]\n\n    def get_queryset(self):\n        queryset = Article.objects.all()\n        published = self.request.query_params.get('published')\n        if published is not None:\n            queryset = queryset.filter(published=published)\n        return queryset\n\n    def perform_create(self, serializer):\n        serializer.save(author=self.request.user)",
      "language": "python",
      "description": "Django REST Frameworkã®ViewSet",
      "tag_ids": [
        6
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "GridSearchCV",
      "code": "from sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\n\n# ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å€™è£œ\nparam_grid = {\n    'n_estimators': [50, 100, 200],\n    'max_depth': [5, 10, 15, None],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4]\n}\n\nmodel = RandomForestClassifier(random_state=42)\n\n# ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ\ngrid_search = GridSearchCV(\n    model,\n    param_grid,\n    cv=5,\n    scoring='accuracy',\n    n_jobs=-1,\n    verbose=1\n)\n\ngrid_search.fit(X_train, y_train)\n\n# æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\nprint(\"æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:\", grid_search.best_params_)\nprint(\"æœ€è‰¯ã‚¹ã‚³ã‚¢:\", grid_search.best_score_)\n\n# æœ€é©ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬\nbest_model = grid_search.best_estimator_\ny_pred = best_model.predict(X_test)",
      "language": "python",
      "description": "ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã§æœ€é©ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¢ç´¢",
      "tag_ids": [
        4
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "GroupBy Operations",
      "code": "import pandas as pd\n\n# ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã¨é›†è¨ˆ\ngrouped = df.groupby('category')\nprint(grouped.mean())\nprint(grouped.sum())\nprint(grouped.count())\n\n# è¤‡æ•°åˆ—ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–\ngrouped = df.groupby(['category', 'region'])\n\n# è¤‡æ•°ã®é›†è¨ˆé–¢æ•°ã‚’é©ç”¨\nresult = df.groupby('category').agg({\n    'sales': ['sum', 'mean', 'count'],\n    'profit': ['sum', 'mean'],\n    'quantity': 'sum'\n})\n\n# ã‚«ã‚¹ã‚¿ãƒ é›†è¨ˆé–¢æ•°\nresult = df.groupby('category').agg({\n    'price': lambda x: x.max() - x.min()\n})\n\nprint(result)",
      "language": "python",
      "description": "DataFrameã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ãƒ»é›†è¨ˆï¼ˆè¤‡æ•°é›†è¨ˆé–¢æ•°å¯¾å¿œï¼‰",
      "tag_ids": [
        3
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "GroupBy and Aggregation",
      "code": "import pandas as pd\n\n# Group by single column\ngrouped = df.groupby('category')\nprint(grouped.mean())\nprint(grouped.sum())\nprint(grouped.count())\n\n# Group by multiple columns\ngrouped = df.groupby(['category', 'region'])\n\n# Multiple aggregations\nresult = df.groupby('category').agg({\n    'sales': ['sum', 'mean', 'count'],\n    'profit': ['sum', 'mean']\n})\n\nprint(result)",
      "language": "python",
      "description": "DataFrameã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ãƒ»é›†è¨ˆ",
      "tag_ids": [
        3
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Histogram",
      "code": "import matplotlib.pyplot as plt\nimport numpy as np\n\ndata = np.random.randn(1000)\n\nplt.figure(figsize=(10, 6))\nplt.hist(data, bins=30, edgecolor='black', alpha=0.7)\nplt.xlabel('Value')\nplt.ylabel('Frequency')\nplt.title('Histogram')\nplt.grid(axis='y', alpha=0.3)\nplt.show()",
      "language": "python",
      "description": "ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’ä½œæˆ",
      "tag_ids": [
        2
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Histogram",
      "code": "import matplotlib.pyplot as plt\nimport numpy as np\n\ndata = np.random.randn(1000)\n\nplt.figure(figsize=(10, 6))\nn, bins, patches = plt.hist(data, bins=30, edgecolor='black', alpha=0.7)\nplt.xlabel('å€¤')\nplt.ylabel('é »åº¦')\nplt.title('ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼ˆæ­£è¦åˆ†å¸ƒï¼‰')\nplt.grid(axis='y', alpha=0.3)\n\n# çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º\nmean = data.mean()\nstd = data.std()\nplt.axvline(mean, color='r', linestyle='--', label=f'å¹³å‡: {mean:.2f}')\nplt.legend()\nplt.show()",
      "language": "python",
      "description": "çµ±è¨ˆæƒ…å ±ä»˜ãã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’ä½œæˆ",
      "tag_ids": [
        2
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Linear Regression",
      "code": "from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Create and train model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Evaluate\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"MSE: {mse:.4f}\")\nprint(f\"RÂ² Score: {r2:.4f}\")",
      "language": "python",
      "description": "ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¨è©•ä¾¡",
      "tag_ids": [
        4
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Linear Regression",
      "code": "from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n\n# ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆã¨è¨“ç·´\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# äºˆæ¸¬\ny_pred = model.predict(X_test)\n\n# è©•ä¾¡\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nmae = mean_absolute_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"MSE: {mse:.4f}\")\nprint(f\"RMSE: {rmse:.4f}\")\nprint(f\"MAE: {mae:.4f}\")\nprint(f\"RÂ² Score: {r2:.4f}\")\n\n# ä¿‚æ•°ã¨åˆ‡ç‰‡\nprint(f\"ä¿‚æ•°: {model.coef_}\")\nprint(f\"åˆ‡ç‰‡: {model.intercept_}\")",
      "language": "python",
      "description": "ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¨è©•ä¾¡ï¼ˆMSE, RMSE, MAE, RÂ²ï¼‰",
      "tag_ids": [
        4
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Matrix Operations",
      "code": "import numpy as np\n\nA = np.array([[1, 2], [3, 4]])\nB = np.array([[5, 6], [7, 8]])\n\n# Matrix multiplication\nC = np.dot(A, B)\n# or\nC = A @ B\n\n# Transpose\nA_T = A.T\n\n# Inverse\nA_inv = np.linalg.inv(A)\n\n# Determinant\ndet = np.linalg.det(A)",
      "language": "python",
      "description": "NumPyã«ã‚ˆã‚‹ç·šå½¢ä»£æ•°æ¼”ç®—",
      "tag_ids": [
        1
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Matrix Operations",
      "code": "import numpy as np\n\nA = np.array([[1, 2], [3, 4]])\nB = np.array([[5, 6], [7, 8]])\n\n# è¡Œåˆ—æ¼”ç®—\nC = np.dot(A, B)      # è¡Œåˆ—ç©\nC = A @ B             # è¡Œåˆ—ç©ï¼ˆæ¼”ç®—å­ï¼‰\nA_T = A.T             # è»¢ç½®\nA_inv = np.linalg.inv(A)  # é€†è¡Œåˆ—\ndet = np.linalg.det(A)    # è¡Œåˆ—å¼\n\n# å›ºæœ‰å€¤ãƒ»å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«\neigenvalues, eigenvectors = np.linalg.eig(A)",
      "language": "python",
      "description": "NumPyã«ã‚ˆã‚‹ç·šå½¢ä»£æ•°æ¼”ç®—ï¼ˆè¡Œåˆ—ç©ã€è»¢ç½®ã€é€†è¡Œåˆ—ã€å›ºæœ‰å€¤ãªã©ï¼‰",
      "tag_ids": [
        1
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Model Definition",
      "code": "from django.db import models\n\nclass Article(models.Model):\n    title = models.CharField(max_length=200)\n    content = models.TextField()\n    author = models.ForeignKey('auth.User', on_delete=models.CASCADE)\n    created_at = models.DateTimeField(auto_now_add=True)\n    updated_at = models.DateTimeField(auto_now=True)\n    published = models.BooleanField(default=False)\n\n    class Meta:\n        ordering = ['-created_at']\n        verbose_name_plural = 'Articles'\n\n    def __str__(self):\n        return self.title",
      "language": "python",
      "description": "ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ãƒƒãƒ—ä»˜ãDjangoãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©",
      "tag_ids": [
        6
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Model Training",
      "code": "# Train the model\nhistory = model.fit(\n    X_train, y_train,\n    batch_size=32,\n    epochs=10,\n    validation_split=0.2,\n    callbacks=[\n        keras.callbacks.EarlyStopping(\n            patience=3,\n            restore_best_weights=True\n        ),\n        keras.callbacks.ModelCheckpoint(\n            'best_model.h5',\n            save_best_only=True\n        )\n    ]\n)\n\n# Evaluate\ntest_loss, test_acc = model.evaluate(X_test, y_test)\nprint(f\"Test accuracy: {test_acc:.4f}\")",
      "language": "python",
      "description": "ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãã§Kerasãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´",
      "tag_ids": [
        5
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Random Forest Classifier",
      "code": "from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\n\n# Create and train model\nmodel = RandomForestClassifier(\n    n_estimators=100,\n    max_depth=10,\n    random_state=42\n)\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Evaluate\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(classification_report(y_test, y_pred))",
      "language": "python",
      "description": "ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆåˆ†é¡å™¨ã®è¨“ç·´",
      "tag_ids": [
        4
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Random Forest Classifier",
      "code": "from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n\n# ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆã¨è¨“ç·´\nmodel = RandomForestClassifier(\n    n_estimators=100,    # æ±ºå®šæœ¨ã®æ•°\n    max_depth=10,        # æœ¨ã®æœ€å¤§æ·±ã•\n    random_state=42,\n    n_jobs=-1            # ä¸¦åˆ—å‡¦ç†\n)\nmodel.fit(X_train, y_train)\n\n# äºˆæ¸¬\ny_pred = model.predict(X_test)\ny_prob = model.predict_proba(X_test)  # ç¢ºç‡\n\n# è©•ä¾¡\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"æ­£è§£ç‡: {accuracy:.4f}\")\nprint(\"\nåˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ:\")\nprint(classification_report(y_test, y_pred))\nprint(\"\næ··åŒè¡Œåˆ—:\")\nprint(confusion_matrix(y_test, y_pred))\n\n# ç‰¹å¾´é‡ã®é‡è¦åº¦\nimportances = model.feature_importances_\nprint(\"\nç‰¹å¾´é‡ã®é‡è¦åº¦:\", importances)",
      "language": "python",
      "description": "ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆåˆ†é¡å™¨ã®è¨“ç·´ã¨è©³ç´°è©•ä¾¡ï¼ˆç‰¹å¾´é‡é‡è¦åº¦å«ã‚€ï¼‰",
      "tag_ids": [
        4
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Random Numbers",
      "code": "import numpy as np\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# Random integers\nrand_int = np.random.randint(0, 10, size=(3, 3))\n\n# Random floats [0, 1)\nrand_float = np.random.random((3, 3))\n\n# Normal distribution\nnormal = np.random.randn(1000)\n\n# Choice\nchoice = np.random.choice([1, 2, 3, 4, 5], size=10)",
      "language": "python",
      "description": "NumPyã§ä¹±æ•°ã‚’ç”Ÿæˆã™ã‚‹",
      "tag_ids": [
        1
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Random Numbers",
      "code": "import numpy as np\n\n# ä¹±æ•°ç”Ÿæˆ\nnp.random.seed(42)  # å†ç¾æ€§ã®ãŸã‚ã®ã‚·ãƒ¼ãƒ‰è¨­å®š\n\n# æ§˜ã€…ãªä¹±æ•°ç”Ÿæˆ\nrand_int = np.random.randint(0, 10, size=(3, 3))\nrand_float = np.random.random((3, 3))\nnormal = np.random.randn(1000)  # æ¨™æº–æ­£è¦åˆ†å¸ƒ\nuniform = np.random.uniform(0, 1, 100)\nchoice = np.random.choice([1, 2, 3, 4, 5], size=10, replace=False)\n\n# é…åˆ—ã®ã‚·ãƒ£ãƒƒãƒ•ãƒ«\narr = np.arange(10)\nnp.random.shuffle(arr)",
      "language": "python",
      "description": "NumPyã§ä¹±æ•°ã‚’ç”Ÿæˆã™ã‚‹æ§˜ã€…ãªæ–¹æ³•ï¼ˆæ­£è¦åˆ†å¸ƒã€ä¸€æ§˜åˆ†å¸ƒãªã©ï¼‰",
      "tag_ids": [
        1
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Save and Load Model",
      "code": "from tensorflow import keras\n\n# Save entire model\nmodel.save('my_model.h5')\n\n# Load model\nloaded_model = keras.models.load_model('my_model.h5')\n\n# Save only weights\nmodel.save_weights('model_weights.h5')\n\n# Load weights\nmodel.load_weights('model_weights.h5')\n\n# Make predictions\npredictions = loaded_model.predict(X_new)",
      "language": "python",
      "description": "Kerasãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¨èª­ã¿è¾¼ã¿",
      "tag_ids": [
        5
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Scatter Plot",
      "code": "import matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.random.randn(100)\ny = np.random.randn(100)\ncolors = np.random.rand(100)\nsizes = 1000 * np.random.rand(100)\n\nplt.figure(figsize=(10, 6))\nplt.scatter(x, y, c=colors, s=sizes, alpha=0.5, cmap='viridis')\nplt.colorbar()\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('Scatter Plot')\nplt.show()",
      "language": "python",
      "description": "ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°ä»˜ãã®æ•£å¸ƒå›³ã‚’ä½œæˆ",
      "tag_ids": [
        2
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Scatter Plot",
      "code": "import matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.random.randn(100)\ny = np.random.randn(100)\ncolors = np.random.rand(100)\nsizes = 1000 * np.random.rand(100)\n\nplt.figure(figsize=(10, 6))\nscatter = plt.scatter(x, y, c=colors, s=sizes, alpha=0.5, cmap='viridis')\nplt.colorbar(scatter)\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('æ•£å¸ƒå›³')\nplt.show()",
      "language": "python",
      "description": "ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°ã¨ã‚µã‚¤ã‚ºå¤‰æ›´ä»˜ãã®æ•£å¸ƒå›³ã‚’ä½œæˆ",
      "tag_ids": [
        2
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Sequential Model",
      "code": "from tensorflow import keras\nfrom tensorflow.keras import layers\n\n# Create Sequential model\nmodel = keras.Sequential([\n    layers.Dense(64, activation='relu', input_shape=(input_dim,)),\n    layers.Dropout(0.2),\n    layers.Dense(32, activation='relu'),\n    layers.Dropout(0.2),\n    layers.Dense(num_classes, activation='softmax')\n])\n\n# Compile model\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nprint(model.summary())",
      "language": "python",
      "description": "Sequentialå‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ",
      "tag_ids": [
        5
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "StandardScaler",
      "code": "from sklearn.preprocessing import StandardScaler\n\n# Create scaler\nscaler = StandardScaler()\n\n# Fit and transform training data\nX_train_scaled = scaler.fit_transform(X_train)\n\n# Transform test data (use same scaler!)\nX_test_scaled = scaler.transform(X_test)\n\n# The scaler can be saved for later use\nimport joblib\njoblib.dump(scaler, 'scaler.pkl')\nloaded_scaler = joblib.load('scaler.pkl')",
      "language": "python",
      "description": "StandardScalerã§ç‰¹å¾´é‡ã‚’æ¨™æº–åŒ–",
      "tag_ids": [
        4
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "StandardScaler",
      "code": "from sklearn.preprocessing import StandardScaler\nimport joblib\n\n# ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®ä½œæˆ\nscaler = StandardScaler()\n\n# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§fitã—ã¦å¤‰æ›\nX_train_scaled = scaler.fit_transform(X_train)\n\n# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¯åŒã˜ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã§å¤‰æ›ï¼ˆfitã—ãªã„ï¼ï¼‰\nX_test_scaled = scaler.transform(X_test)\n\n# ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®ä¿å­˜ï¼ˆæœ¬ç•ªç’°å¢ƒã§ä½¿ç”¨ï¼‰\njoblib.dump(scaler, 'scaler.pkl')\n\n# ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®èª­ã¿è¾¼ã¿\nloaded_scaler = joblib.load('scaler.pkl')\nX_new_scaled = loaded_scaler.transform(X_new)",
      "language": "python",
      "description": "StandardScalerã§ç‰¹å¾´é‡ã‚’æ¨™æº–åŒ–ï¼ˆå¹³å‡0ã€åˆ†æ•£1ï¼‰",
      "tag_ids": [
        4
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Subplots",
      "code": "import matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(0, 10, 100)\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\naxes[0, 0].plot(x, np.sin(x))\naxes[0, 0].set_title('sin(x)')\n\naxes[0, 1].plot(x, np.cos(x))\naxes[0, 1].set_title('cos(x)')\n\naxes[1, 0].plot(x, np.tan(x))\naxes[1, 0].set_title('tan(x)')\n\naxes[1, 1].plot(x, x**2)\naxes[1, 1].set_title('xÂ²')\n\nplt.tight_layout()\nplt.show()",
      "language": "python",
      "description": "ã‚°ãƒªãƒƒãƒ‰çŠ¶ã«è¤‡æ•°ã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã‚’ä½œæˆ",
      "tag_ids": [
        2
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Subplots",
      "code": "import matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(0, 10, 100)\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\naxes[0, 0].plot(x, np.sin(x))\naxes[0, 0].set_title('sin(x)')\n\naxes[0, 1].plot(x, np.cos(x), 'r')\naxes[0, 1].set_title('cos(x)')\n\naxes[1, 0].plot(x, np.tan(x))\naxes[1, 0].set_title('tan(x)')\n\naxes[1, 1].plot(x, x**2)\naxes[1, 1].set_title('xÂ²')\n\nplt.tight_layout()\nplt.show()",
      "language": "python",
      "description": "ã‚°ãƒªãƒƒãƒ‰çŠ¶ã«è¤‡æ•°ã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã‚’ä½œæˆï¼ˆ2Ã—2ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼‰",
      "tag_ids": [
        2
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Train-Test Split",
      "code": "from sklearn.model_selection import train_test_split\n\n# Split data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    test_size=0.2,      # 20% for testing\n    random_state=42,    # For reproducibility\n    stratify=y          # Maintain class distribution\n)\n\nprint(f\"Train size: {len(X_train)}\")\nprint(f\"Test size: {len(X_test)}\")",
      "language": "python",
      "description": "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¨“ç·´ç”¨ã¨ãƒ†ã‚¹ãƒˆç”¨ã«åˆ†å‰²",
      "tag_ids": [
        4
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "Train-Test Split",
      "code": "from sklearn.model_selection import train_test_split\n\n# ãƒ‡ãƒ¼ã‚¿ã‚’è¨“ç·´ç”¨ã¨ãƒ†ã‚¹ãƒˆç”¨ã«åˆ†å‰²\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    test_size=0.2,      # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰²åˆï¼ˆ20%ï¼‰\n    random_state=42,    # å†ç¾æ€§ã®ãŸã‚ã®ã‚·ãƒ¼ãƒ‰\n    stratify=y          # ã‚¯ãƒ©ã‚¹æ¯”ç‡ã‚’ç¶­æŒ\n)\n\nprint(f\"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(X_train)}\")\nprint(f\"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(X_test)}\")",
      "language": "python",
      "description": "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¨“ç·´ç”¨ã¨ãƒ†ã‚¹ãƒˆç”¨ã«åˆ†å‰²ï¼ˆstratifyå¯¾å¿œï¼‰",
      "tag_ids": [
        4
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    },
    {
      "name": "URL Patterns",
      "code": "from django.urls import path\nfrom . import views\n\napp_name = 'articles'\n\nurlpatterns = [\n    path('', views.ArticleListView.as_view(), name='list'),\n    path('<int:pk>/', views.ArticleDetailView.as_view(), name='detail'),\n    path('create/', views.ArticleCreateView.as_view(), name='create'),\n    path('<int:pk>/update/', views.ArticleUpdateView.as_view(), name='update'),\n    path('<int:pk>/delete/', views.ArticleDeleteView.as_view(), name='delete'),\n]",
      "language": "python",
      "description": "Djangoã‚¢ãƒ—ãƒªã®URLãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®šç¾©",
      "tag_ids": [
        6
      ],
      "usage_count": 0,
      "created_at": null,
      "updated_at": null
    }
  ]
}